{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code creates a Torch Dataset of predictors and targets for HAL_GRU to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os.path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_delayed_dataset(predictors, targets, lookback = 300):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(targets)-lookback-1):\n",
    "        predictor = predictors[i:(i+lookback), :]\n",
    "        target = targets[i + lookback]\n",
    "        dataX.append(predictor)\n",
    "        dataY.append(target)\n",
    "\n",
    "    dataX = torch.tensor(dataX)\n",
    "    dataY = torch.tensor(dataY)\n",
    "    #Convert to float tensors\n",
    "    return dataX, dataY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant:  1  Tool:  1  Trial:  1\n",
      "Participant:  1  Tool:  1  Trial:  2\n",
      "Participant:  1  Tool:  1  Trial:  3\n",
      "Participant:  1  Tool:  2  Trial:  1\n",
      "Participant:  1  Tool:  2  Trial:  2\n",
      "Participant:  1  Tool:  2  Trial:  3\n",
      "Participant:  2  Tool:  1  Trial:  1\n",
      "Participant:  2  Tool:  1  Trial:  2\n",
      "Participant:  2  Tool:  1  Trial:  3\n",
      "Participant:  2  Tool:  2  Trial:  1\n",
      "Participant:  2  Tool:  2  Trial:  2\n",
      "Participant:  2  Tool:  2  Trial:  3\n",
      "Participant:  3  Tool:  1  Trial:  1\n",
      "Participant:  3  Tool:  1  Trial:  2\n",
      "Participant:  3  Tool:  1  Trial:  3\n",
      "Participant:  3  Tool:  2  Trial:  1\n",
      "Participant:  3  Tool:  2  Trial:  2\n",
      "Participant:  4  Tool:  1  Trial:  1\n",
      "Participant:  4  Tool:  1  Trial:  2\n",
      "Participant:  4  Tool:  2  Trial:  1\n",
      "Participant:  4  Tool:  2  Trial:  2\n",
      "Participant:  5  Tool:  1  Trial:  1\n",
      "Participant:  5  Tool:  1  Trial:  2\n",
      "Participant:  5  Tool:  2  Trial:  1\n",
      "Participant:  5  Tool:  2  Trial:  2\n",
      "Participant:  6  Tool:  1  Trial:  1\n",
      "Participant:  6  Tool:  1  Trial:  2\n",
      "Participant:  6  Tool:  2  Trial:  1\n",
      "Participant:  6  Tool:  2  Trial:  2\n",
      "Participant:  7  Tool:  1  Trial:  1\n",
      "Participant:  7  Tool:  1  Trial:  2\n",
      "Participant:  7  Tool:  2  Trial:  1\n",
      "Participant:  7  Tool:  2  Trial:  2\n",
      "Participant:  8  Tool:  1  Trial:  1\n",
      "Participant:  8  Tool:  2  Trial:  1\n",
      "Participant:  9  Tool:  1  Trial:  1\n",
      "Participant:  9  Tool:  2  Trial:  1\n",
      "Participant:  10  Tool:  1  Trial:  1\n",
      "Participant:  10  Tool:  2  Trial:  1\n",
      "Participant:  11  Tool:  1  Trial:  1\n",
      "Participant:  11  Tool:  2  Trial:  1\n",
      "Participant:  12  Tool:  1  Trial:  1\n",
      "Participant:  12  Tool:  2  Trial:  1\n",
      "Participant:  13  Tool:  1  Trial:  1\n",
      "Participant:  13  Tool:  2  Trial:  1\n",
      "Participant:  14  Tool:  1  Trial:  1\n",
      "Participant:  14  Tool:  1  Trial:  2\n",
      "Participant:  14  Tool:  1  Trial:  3\n",
      "Participant:  14  Tool:  2  Trial:  1\n",
      "Participant:  14  Tool:  2  Trial:  2\n",
      "Participant:  15  Tool:  1  Trial:  1\n",
      "Participant:  15  Tool:  2  Trial:  1\n"
     ]
    }
   ],
   "source": [
    "participant_id_range = range(1,16)\n",
    "tool_id_range = range(1,3)\n",
    "trial_id_range = range(1,4)\n",
    "output_directory = r'C:\\Users\\anand\\Desktop\\HAL Pytorch Datasets'\n",
    "# Create a dataset for time-series modeling with a Gated Recurrent Unit (GRU)\n",
    "# This dataset reads data from the HAL Labelled Data directory\n",
    "# Creating separate datasets for each participant, tool, and hand\n",
    "# The columns of the csv files are\n",
    "#Time (s), Left Palm Force (N), Left Thumb Force (N), Left Index Force (N), Left Middle Force (N),Left Ring Force (N),\n",
    "#Left Little Force (N),\tRight Palm Force (N), Right Thumb Force (N), Right Index Force (N), Right Middle Force (N), \n",
    "#Right Ring Force (N), Right Little Force (N), Left HAL\tRight HAL\n",
    "\n",
    "# The dataset consists of 6 predictors, 1 total hand force = sum of all forces and 5 finger forces\n",
    "# The dataset is initially downsampled by deleting half of the rows\n",
    "# Then, 6 predictors with 300 samples are used to predict the 301th HAL score.\n",
    "# Then, these predictors are moved down by one row and rows 2-301 are used to predict 302th HAL score\n",
    "# Save a separate dataset for each participant and tool combo. Eg: p1_tool1.pt\n",
    "for participant_id in participant_id_range:\n",
    "    for tool_id in tool_id_range:\n",
    "        left_dataset = {}\n",
    "        right_dataset = {}  \n",
    "        for trial_id in trial_id_range:            \n",
    "            file_name = r'C:\\Users\\anand\\Desktop\\HAL Labelled Data\\p'+str(participant_id)+\" tool\"+str(tool_id)+\" trial\"+str(trial_id)+' w lr HAL.csv'\n",
    "            # Create an empty tensor dataset\n",
    "\n",
    "            if os.path.isfile(file_name):\n",
    "                print('Participant: ',participant_id,' Tool: ',tool_id,' Trial: ',trial_id)\n",
    "                df_temp = pd.read_csv(file_name)\n",
    "                # Delete every alternate row\n",
    "                df_temp = df_temp.iloc[::2]\n",
    "                left_predictor_names = ['Left Palm Force (N)','Left Thumb Force (N)','Left Index Force (N)','Left Middle Force (N)','Left Ring Force (N)','Left Little Force (N)']\n",
    "                left_target_name = 'Left HAL'\n",
    "                left_force_sum = df_temp[left_predictor_names].sum(axis=1)\n",
    "                left_finger_forces = df_temp[left_predictor_names[1:]]\n",
    "                left_predictors = np.array(pd.concat([left_force_sum,left_finger_forces],axis=1))\n",
    "                left_target = np.array(df_temp[left_target_name])\n",
    "                left_dataX, left_dataY = create_time_delayed_dataset(left_predictors, left_target)\n",
    "                left_dataset[str(participant_id)+'_'+str(tool_id)+'_'+str(trial_id)] = (left_dataX, left_dataY)\n",
    "\n",
    "                right_predictor_names = ['Right Palm Force (N)','Right Thumb Force (N)','Right Index Force (N)','Right Middle Force (N)','Right Ring Force (N)','Right Little Force (N)']\n",
    "                right_target_name = 'Right HAL'\n",
    "                right_force_sum = df_temp[right_predictor_names].sum(axis=1)\n",
    "                right_finger_forces = df_temp[right_predictor_names[1:]]\n",
    "                right_predictors = np.array(pd.concat([right_force_sum,right_finger_forces],axis=1))\n",
    "                right_target = np.array(df_temp[right_target_name])\n",
    "                right_dataX, right_dataY = create_time_delayed_dataset(right_predictors, right_target)\n",
    "                right_dataset[str(participant_id)+'_'+str(tool_id)+'_'+str(trial_id)] = (right_dataX, right_dataY)\n",
    "                # Concatenate datasets with the same tool id and hand\n",
    "        # Save the dataset\n",
    "        left_file_name = 'p'+str(participant_id)+'_tool'+str(tool_id)+'_left.pt'\n",
    "        left_predictors_combined = torch.cat([left_dataset[key][0] for key in left_dataset.keys()])\n",
    "        left_target_combined = torch.cat([left_dataset[key][1] for key in left_dataset.keys()])\n",
    "        left_XY = torch.utils.data.TensorDataset(left_predictors_combined, left_target_combined)\n",
    "        torch.save(left_XY,os.path.join(output_directory,left_file_name))\n",
    "\n",
    "        right_file_name = 'p'+str(participant_id)+'_tool'+str(tool_id)+'_right.pt'\n",
    "        right_predictors_combined = torch.cat([right_dataset[key][0] for key in right_dataset.keys()])\n",
    "        right_target_combined = torch.cat([right_dataset[key][1] for key in right_dataset.keys()])\n",
    "        right_XY = torch.utils.data.TensorDataset(right_predictors_combined, right_target_combined)\n",
    "        torch.save(right_XY,os.path.join(output_directory,right_file_name))\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([23887, 300, 6])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_predictors_combined.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ergo_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
